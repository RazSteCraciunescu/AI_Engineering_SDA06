{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Capitol 1: Introducere în Clasificare\n",
        "\n",
        "Bun venit la acest nou capitol despre **Machine Learning**! Astăzi vom explora unul dintre cele mai importante și mai des întâlnite concepte: **clasificarea**. Imaginați-vă că sunteți un poștaș care trebuie să sorteze scrisorile în diferite cutii poștale, fiecare cutie reprezentând o categorie. În esență, asta face un model de clasificare: atribuie o etichetă sau o categorie unor date de intrare.\n",
        "\n",
        "Spre deosebire de **regresie**, unde scopul este să prezicem o valoare numerică continuă (cum ar fi prețul unei case), în **clasificare** prezicem o etichetă discretă. De exemplu, un e-mail este **spam** sau **nu este spam**? O tumoare este **malignă** sau **benignă**?  Acestea sunt probleme de clasificare."
      ],
      "metadata": {
        "id": "intro_clasificare"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tipuri de Clasificare\n",
        "\n",
        "Există două tipuri principale de clasificare, în funcție de numărul de \"cutii\" în care trebuie să sortăm datele:\n",
        "\n",
        "* **Clasificare Binară**: Când avem doar două categorii posibile. Este cel mai simplu și cel mai comun tip. Exemplu: **DA** sau **NU**, **ADEVĂRAT** sau **FALS**, **SPAM** sau **NON-SPAM**.\n",
        "* **Clasificare Multi-clasă**: Când avem mai mult de două categorii. Exemplu: clasificarea speciilor de flori (Setosa, Versicolor, Virginica)  sau recunoașterea cifrelor scrise de mână (0, 1, 2, ..., 9)."
      ],
      "metadata": {
        "id": "tipuri_clasificare"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cum funcționează? Modelul de învățare\n",
        "\n",
        "Un model de clasificare învață dintr-un set de date de antrenament (**training set**), unde fiecare exemplu are asociată o etichetă corectă. Gândiți-vă la acest proces ca la un student care învață pentru un examen: el primește probleme rezolvate (datele de antrenament cu etichete) și, pe baza lor, învață un model general pentru a rezolva probleme noi, nevăzute (datele de test).\n",
        "\n",
        "Pentru a ne asigura că modelul nostru nu doar memorează răspunsurile, ci generalizează bine, vom împărți setul de date în două:\n",
        "1.  **Setul de antrenament (Training Set)**: Folosit pentru a \"învăța\" modelul. De obicei, reprezintă 70-80% din date.\n",
        "2.  **Setul de testare (Testing Set)**: Folosit pentru a evalua performanța modelului pe date noi."
      ],
      "metadata": {
        "id": "model_invatare"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplu 1: Împărțirea datelor în set de antrenament și de test\n",
        "# Vom folosi o funcție foarte utilă din biblioteca scikit-learn.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Generăm un set de date simplu: 100 de exemple cu 2 caracteristici (features)\n",
        "X = np.random.rand(100, 2)\n",
        "# Generăm etichete binare (0 sau 1) pentru fiecare exemplu\n",
        "y = np.random.randint(2, size=100)\n",
        "\n",
        "# Împărțim datele: 80% pentru antrenament, 20% pentru testare\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Dimensiune X_train: {X_train.shape}\")\n",
        "print(f\"Dimensiune X_test: {X_test.shape}\")\n",
        "print(f\"Dimensiune y_train: {y_train.shape}\")\n",
        "print(f\"Dimensiune y_test: {y_test.shape}\")\n",
        "\n",
        "# OBS.: random_state=42 asigură că împărțirea datelor este mereu aceeași.\n",
        "# Acest lucru este important pentru reproductibilitatea rezultatelor. Putem\n",
        "# folosi orice număr."
      ],
      "metadata": {
        "id": "split_data_example"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# __EXERCIȚIU__\n",
        "# Se dă un set de date X_exercitiu cu 200 de intrări și 3 caracteristici,\n",
        "# și un set de etichete y_exercitiu.\n",
        "# Împărțiți datele într-un set de antrenament (75%) și unul de testare (25%).\n",
        "# Afișați dimensiunile seturilor rezultate.\n",
        "\n",
        "X_exercitiu = np.random.rand(200, 3)\n",
        "y_exercitiu = np.random.randint(3, size=200) # 3 clase posibile (0, 1, 2)\n",
        "\n",
        "# HINT: Folosiți funcția train_test_split și modificați parametrul test_size.\n"
      ],
      "metadata": {
        "id": "split_data_exercitiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problema Seturilor de Date Dezechilibrate și Stratificarea\n",
        "\n",
        "Să zicem că avem un set de date pentru detecția fraudelor bancare, unde 99% din tranzacții sunt legitime și doar 1% sunt frauduloase. Dacă împărțim datele aleatoriu, există o șansă ca setul nostru de testare să nu conțină **nicio** tranzacție frauduloasă! Cum putem evalua un model în acest caz?\n",
        "\n",
        "Aici intervine **stratificarea**. Când împărțim datele, ne asigurăm că proporția claselor (de ex., 1% fraude, 99% legitime) se păstrează atât în setul de antrenament, cât și în cel de testare. Acest lucru garantează o evaluare mult mai corectă a performanței modelului.\n",
        "\n",
        "În `scikit-learn`, acest lucru se face foarte simplu folosind parametrul `stratify`."
      ],
      "metadata": {
        "id": "stratification_intro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplu 2: Împărțire stratificată\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Creăm un set de date dezechilibrat: 90 de exemple clasa 0, 10 de exemple clasa 1\n",
        "X_dezechilibrat = np.random.rand(100, 2)\n",
        "y_dezechilibrat = np.array([0] * 90 + [1] * 10)\n",
        "\n",
        "# Împărțim datele FĂRĂ stratificare\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_dezechilibrat, y_dezechilibrat, test_size=0.2, random_state=42)\n",
        "print(f\"Proporție clasa 1 în y_test (fără stratificare): {np.mean(y_test) * 100}%\")\n",
        "\n",
        "# Împărțim datele CU stratificare\n",
        "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_dezechilibrat, y_dezechilibrat,\n",
        "                                                          test_size=0.2, random_state=42,\n",
        "                                                          stratify=y_dezechilibrat)\n",
        "print(f\"Proporție clasa 1 în y_test (CU stratificare): {np.mean(y_test_s) * 100}%\")\n",
        "\n",
        "# OBS.: Observați cum, cu stratificare, setul de testare păstrează proporția\n",
        "# de 10% a clasei minoritare, asigurând o evaluare corectă. Fără stratificare,\n",
        "# unele cazuri pot fi utilizabile, dar se putea întâmpla ca y_test să fie\n",
        "# format doar din 0."
      ],
      "metadata": {
        "id": "stratification_example"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setul de Date Iris\n",
        "\n",
        "Acest set de date conține 150 de observații despre trei specii de flori Iris (Setosa, Versicolor și Virginica). Pentru fiecare floare, au fost măsurate 4 caracteristici:\n",
        "\n",
        "1.  Lungimea sepalei (sepal length)\n",
        "2.  Lățimea sepalei (sepal width)\n",
        "3.  Lungimea petalei (petal length)\n",
        "4.  Lățimea petalei (petal width)\n",
        "\n",
        "Scopul nostru este să antrenăm un model care, pe baza acestor 4 măsurători, poate clasifica corect specia florii. Aceasta este o problemă de **clasificare multi-clasă**."
      ],
      "metadata": {
        "id": "iris_intro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplu 3: Încărcarea și împărțirea setului de date Iris\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# Încărcăm setul de date\n",
        "iris = load_iris()\n",
        "X_iris = iris.data\n",
        "y_iris = iris.target\n",
        "\n",
        "print(\"Forma datelor (X):\", X_iris.shape)\n",
        "print(\"Forma etichetelor (y):\", y_iris.shape)\n",
        "print(\"Numele caracteristicilor:\", iris.feature_names)\n",
        "print(\"Numele claselor (speciilor):\", iris.target_names)\n",
        "\n",
        "# Vom împărți datele într-un set de antrenament (70%) și unul de testare (30%).\n",
        "# Vom folosi stratificarea pentru a ne asigura că fiecare specie este\n",
        "# reprezentată corect.\n",
        "\n",
        "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(X_iris, y_iris, test_size=0.3, random_state=42, stratify=y_iris)\n",
        "\n",
        "print(\"\\n--- După împărțire ---\")\n",
        "print(\"Forma X_train:\", X_train_iris.shape)\n",
        "print(\"Forma X_test:\", X_test_iris.shape)\n",
        "\n",
        "# Verificăm proporțiile în setul de test\n",
        "print(\"Număr exemple per clasă în y_test:\", np.bincount(y_test_iris))\n",
        "\n",
        "# OBS.: `np.bincount` numără aparițiile fiecărei valori (0, 1, 2). Observăm că avem exact 15 exemple\n",
        "# pentru fiecare clasă, ceea ce demonstrează o stratificare perfectă."
      ],
      "metadata": {
        "id": "iris_split_example"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___"
      ],
      "metadata": {
        "id": "separator_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Capitol 2: Evaluarea Modelelor de Clasificare\n",
        "\n",
        "După ce am antrenat un model, cum știm dacă este bun? Aici intervin **metricile de evaluare**. Acestea sunt ca niște note pe care le dăm modelului nostru pentru a vedea cât de bine a \"învățat\". Cea mai simplă metrică este **acuratețea (accuracy)**, care ne spune procentul de predicții corecte.\n",
        "\n",
        "Totuși, acuratețea poate fi înșelătoare, mai ales când clasele sunt dezechilibrate (de exemplu, avem 99 de e-mailuri normale și doar 1 de tip spam). Un model care prezice mereu \"non-spam\" ar avea o acuratețe de 99%, dar ar fi complet inutil. De aceea, avem nevoie de unelte mai bune."
      ],
      "metadata": {
        "id": "evaluare_modele"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matricea de Confuzie (Confusion Matrix)\n",
        "\n",
        "**Matricea de confuzie** este un tabel care ne arată în detaliu unde a greșit și unde a nimerit modelul nostru. Pentru o problemă de clasificare binară, arată astfel:\n",
        "\n",
        "|               | Predicție: Pozitiv | Predicție: Negativ |\n",
        "|---------------|--------------------|--------------------|\n",
        "| **Real: Pozitiv** | True Positive (TP) | False Negative (FN) |\n",
        "| **Real: Negativ** | False Positive (FP)| True Negative (TN) |\n",
        "\n",
        "**Analogia medicului**:\n",
        "-   `TP (True Positive)`: Pacientul are boala, iar medicul (modelul) a diagnosticat corect boala. (Bravo!)\n",
        "-   `TN (True Negative)`: Pacientul NU are boala, iar medicul a diagnosticat corect că este sănătos. (Bravo!)\n",
        "-   `FP (False Positive)`: Pacientul este sănătos, dar medicul l-a diagnosticat greșit cu boala. (Alarmă falsă, Eroare de Tip I)\n",
        "-   `FN (False Negative)`: Pacientul are boala, dar medicul a ratat diagnosticul. (Cea mai periculoasă eroare, Eroare de Tip II)"
      ],
      "metadata": {
        "id": "matrice_confuzie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplu 4: Calcularea matricei de confuzie\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_real =    [1, 0, 1, 1, 0, 1, 0, 0, 1, 0] # 1 = are boala, 0 = sanatos\n",
        "y_pred_model = [1, 0, 1, 0, 0, 1, 1, 0, 1, 0] # Predictiile modelului\n",
        "\n",
        "matrice = confusion_matrix(y_real, y_pred_model)\n",
        "print(\"Matricea de confuzie:\\n\", matrice)\n",
        "\n",
        "# OBS.: Matricea este afișată în formatul:\n",
        "# [[TN, FP],\n",
        "#  [FN, TP]]\n",
        "# Așadar, avem: TN=4, FP=1, FN=1, TP=4"
      ],
      "metadata": {
        "id": "confusion_matrix_example"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Precizie, Recall și F1-Score\n",
        "\n",
        "Pe baza matricei de confuzie, putem calcula metrici mai avansate:\n",
        "\n",
        "* **Acuratețea (Accuracy)**: Măsoară cât de aproape sunt săgețile de centrul țintei, în medie. În Machine Learning, este procentul total de predicții corecte (`(TP + TN) / Total`). Este o metrică generală bună, dar poate fi înșelătoare.\n",
        "\n",
        "* **Precizia (Precision)**: Din toate cazurile pe care modelul le-a prezis ca fiind pozitive, câte au fost *cu adevărat* pozitive?  (Formula: `TP / (TP + FP)`). O precizie mare este importantă când vrem să evităm alarmele false (ex: filtrarea de spam).\n",
        "\n",
        "* **Recall (Sensibilitate)**: Din toate cazurile care erau *cu adevărat* pozitive, câte a reușit modelul să le identifice?  (Formula: `TP / (TP + FN)`). Un recall mare este vital când este periculos să ratăm un caz pozitiv (ex: diagnosticarea cancerului).\n",
        "\n",
        "* **F1-Score**: O medie armonică între precizie și recall. Este utilă când dorim un echilibru între cele două.\n",
        "\n",
        "\n",
        "**Când este Precizia mai importantă decât Acuratețea?**\n",
        "Imaginați-vă un filtru de spam. Aici, o eroare de tip **False Positive** (un e-mail important este marcat ca spam) este mult mai gravă decât un **False Negative** (un e-mail spam ajunge în inbox). Vrem să fim foarte siguri că atunci când spunem \"acesta este spam\", avem dreptate. Prin urmare, ne dorim o **precizie** foarte mare, chiar dacă asta înseamnă că mai scăpăm câteva e-mailuri de spam (adică avem un recall mai mic)."
      ],
      "metadata": {
        "id": "precision_recall_f1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplu 5: Calcularea Preciziei, Recall-ului și F1-Score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "acuratete = accuracy_score(y_real, y_pred_model)\n",
        "precizie = precision_score(y_real, y_pred_model)\n",
        "recall = recall_score(y_real, y_pred_model)\n",
        "f1 = f1_score(y_real, y_pred_model)\n",
        "\n",
        "print(f\"Acuratețe: {acuratete:.2f}\") # (4+4)/(4+1+1+4) = 0.80\n",
        "print(f\"Precizie: {precizie:.2f}\")   # 4/(4+1) = 0.80\n",
        "print(f\"Recall: {recall:.2f}\")     # 4/(4+1) = 0.80\n",
        "print(f\"F1-Score: {f1:.2f}\")\n",
        "\n",
        "# OBS.: În acest caz particular, precizia și recall-ul sunt egale, dar acest lucru\n",
        "# se întâmplă rar în practică."
      ],
      "metadata": {
        "id": "metrics_example"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# __EXERCIȚIU__\n",
        "# Se dă o listă de recenzii pentru un produs, unde 1 înseamnă recenzie pozitivă\n",
        "# și 0 înseamnă recenzie negativă.\n",
        "# y_real_reviews: [1, 1, 0, 1, 0, 0, 1, 1, 0, 0]\n",
        "# Un model de clasificare a prezis următoarele etichete:\n",
        "# y_pred_reviews: [1, 0, 1, 1, 0, 1, 1, 1, 0, 0]\n",
        "# Calculați și afișați matricea de confuzie, acuratețea, precizia, recall-ul și\n",
        "# F1-score.\n",
        "\n",
        "# HINT: Folosiți funcțiile din sklearn.metrics importate mai sus."
      ],
      "metadata": {
        "id": "metrics_exercitiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sub-antrenare vs. Supra-antrenare (Underfitting & Overfitting)\n",
        "\n",
        "Acestea sunt două dintre cele mai comune probleme în Machine Learning și reprezintă un echilibru delicat. Să folosim analogia unui student care se pregătește pentru un examen.\n",
        "\n",
        "* **Sub-antrenare (Underfitting)**: Studentul a citit doar titlurile capitolelor. Modelul său mental este prea simplu. El nu va performa bine nici pe problemele pe care le-a mai văzut (datele de antrenament), nici pe cele noi (datele de test). **Modelul este prea simplu** pentru a captura complexitatea datelor.\n",
        "\n",
        "* **Supra-antrenare (Overfitting)**: Studentul a memorat fiecare exemplu din manual, cuvânt cu cuvânt. El poate răspunde perfect la întrebările pe care le-a mai văzut (performanță excelentă pe datele de antrenament), dar când primește o întrebare nouă, formulată puțin diferit, nu știe să răspundă. **Modelul este prea complex** și a învățat zgomotul și detaliile specifice din datele de antrenament, în loc să învețe regula generală.\n",
        "\n",
        "\n",
        "\n",
        "**Scopul nostru** este să găsim un model echilibrat, care generalizează bine pe date noi. Tehnicile de validare, precum **cross-validation**, ne ajută să detectăm overfitting-ul, deoarece evaluăm modelul pe date pe care nu le-a \"memorat\"."
      ],
      "metadata": {
        "id": "under_overfitting"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "___"
      ],
      "metadata": {
        "id": "separator_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Capitol 3: Algoritmi Fundamentali de Clasificare\n",
        "\n",
        "Acum că știm cum să evaluăm un model, haideți să vedem câțiva dintre cei mai populari algoritmi de clasificare."
      ],
      "metadata": {
        "id": "algoritmi_fundamentali"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresia Logistică (Logistic Regression)\n",
        "\n",
        "Nu vă lăsați păcăliți de nume! Deși conține cuvântul \"regresie\", acest algoritm este folosit pentru **clasificare**.  Este o extensie a regresiei liniare. În loc să returneze o valoare numerică directă, folosește o funcție specială numită **funcția sigmoidă** pentru a \"strivi\" rezultatul între 0 și 1. Acest rezultat poate fi interpretat ca o probabilitate. De exemplu, dacă rezultatul este 0.8, înseamnă că modelul este 80% sigur că exemplul aparține clasei pozitive (eticheta 1).\n",
        "\n",
        "\n",
        "\n",
        "De obicei, se stabilește un prag (de ex. 0.5): dacă probabilitatea este mai mare de 0.5, prezicem clasa 1, altfel prezicem clasa 0."
      ],
      "metadata": {
        "id": "regresie_logistica"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplu 6: Antrenarea unui model de Regresie Logistică\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generăm un set de date sintetic pentru clasificare binară\n",
        "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creăm și antrenăm modelul\n",
        "model_logreg = LogisticRegression()\n",
        "model_logreg.fit(X_train, y_train)\n",
        "\n",
        "# Facem predicții pe setul de test\n",
        "predictii = model_logreg.predict(X_test)\n",
        "\n",
        "acuratete = accuracy_score(y_test, predictii)\n",
        "print(f\"Acuratețea modelului de Regresie Logistică: {acuratete:.2f}\")\n",
        "\n",
        "# OBS.: Procesul este foarte simplu în scikit-learn:\n",
        "# 1. Inițiem modelul (ex: LogisticRegression())\n",
        "# 2. Îl antrenăm cu datele de training (ex: .fit(X_train, y_train))\n",
        "# 3. Facem predicții (ex: .predict(X_test))"
      ],
      "metadata": {
        "id": "logreg_example"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplu 7: Regresie Logistică & Vizualizare - Set de date Iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Folosim doar 2 caracteristici pentru vizualizare: lungimea și lățimea petalei\n",
        "X_train_viz = X_train_iris[:, 2:]\n",
        "X_test_viz = X_test_iris[:, 2:]\n",
        "\n",
        "# Antrenăm modelul\n",
        "model_logreg_iris = LogisticRegression(random_state=42)\n",
        "model_logreg_iris.fit(X_train_viz, y_train_iris)\n",
        "\n",
        "# Evaluăm modelul\n",
        "y_pred = model_logreg_iris.predict(X_test_viz)\n",
        "acuratete = accuracy_score(y_test_iris, y_pred)\n",
        "print(f\"Acuratețea Regresiei Logistice (pe 2 feature-uri): {acuratete:.2f}\\n\")\n",
        "\n",
        "# Vizualizăm granițele de decizie\n",
        "x_min, x_max = X_iris[:, 2].min() - 0.5, X_iris[:, 2].max() + 0.5\n",
        "y_min, y_max = X_iris[:, 3].min() - 0.5, X_iris[:, 3].max() + 0.5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
        "Z = model_logreg_iris.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)\n",
        "sns.scatterplot(x=X_test_iris[:, 2], y=X_test_iris[:, 3], hue=iris.target_names[y_test_iris], palette='deep')\n",
        "plt.xlabel('Lungimea Petalei (cm)')\n",
        "plt.ylabel('Lățimea Petalei (cm)')\n",
        "plt.title('Regresia Logistică - Granițe de Decizie pe Datele Iris')\n",
        "plt.show()\n",
        "\n",
        "# OBS.: Graficul arată cum modelul a \"învățat\" trei regiuni distincte. Orice\n",
        "# floare nouă care, prin măsurătorile sale, pică într-una din aceste regiuni\n",
        "# colorate, va fi clasificată corespunzător."
      ],
      "metadata": {
        "id": "logreg_iris_example"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# __EXERCIȚIU__\n",
        "# Să presupunem că avem un set de date despre studenți. Avem două\n",
        "# caracteristici:\n",
        "# - ore_studiu (câte ore pe săptămână studiază)\n",
        "# - participare_curs (numărul de cursuri la care au participat)\n",
        "# Eticheta este 1 dacă studentul a promovat examenul și 0 dacă a picat.\n",
        "\n",
        "# Datele sunt:\n",
        "X_studenti = np.array([[5, 10], [10, 15], [3, 8], [8, 12], [12, 18], [2, 5], [6, 11], [15, 20]])\n",
        "y_studenti = np.array([0, 1, 0, 1, 1, 0, 0, 1])\n",
        "\n",
        "# 1. Antrenați un model de Regresie Logistică pe aceste date.\n",
        "# 2. Preziceți dacă un student care a studiat 7 ore și a participat la 13\n",
        "# cursuri va promova.\n",
        "# 3. Preziceți pentru un student care a studiat 4 ore și a participat la 6\n",
        "# cursuri.\n",
        "\n",
        "# HINT: Nu este nevoie să împărțiți datele în train/test deoarece vrem să\n",
        "# folosim tot setul pentru învățare. Pentru a face o predicție pentru un singur\n",
        "# exemplu, trebuie să-l transmitem ca o listă de liste.\n",
        "# Ex.: Prezicem dacă un student care a stdiat 15 ore și a participat la 20\n",
        "# de cursuri va promova astfel: model.predict([[15, 20]])."
      ],
      "metadata": {
        "id": "logreg_exercitiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Nearest Neighbors (KNN)\n",
        "\n",
        "**KNN** este unul dintre cei mai intuitivi algoritmi de clasificare. Analogia de bază este: \"Spune-mi cine îți sunt prietenii (vecinii), și îți voi spune cine ești\".\n",
        "\n",
        "**Cum funcționează?**\n",
        "1.  Alege un număr `K` de vecini (de obicei un număr impar mic, ca 3, 5 sau 7).\n",
        "2.  Pentru un nou punct de date pe care vrei să-l clasifici, algoritmul se uită la cei mai apropiați `K` vecini din setul de antrenament.\n",
        "3.  Noul punct primește eticheta care apare cel mai des printre acei `K` vecini (vot majoritar).\n",
        "\n",
        "! **IMPORTANT**: Deoarece KNN se bazează pe distanță, este esențial ca datele să fie **scalate** (aduse la aceeași scară) înainte de a folosi algoritmul.  Altfel, o caracteristică cu valori mari (ex: salariul) ar putea domina una cu valori mici (ex: vârsta)."
      ],
      "metadata": {
        "id": "knn_intro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplu 8: Antrenarea unui model KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Folosim același set de date ca la Regresia Logistică\n",
        "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. Scalăm datele\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 2. Creăm și antrenăm modelul cu K=5\n",
        "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
        "model_knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 3. Facem predicții\n",
        "predictii_knn = model_knn.predict(X_test_scaled)\n",
        "\n",
        "acuratete_knn = accuracy_score(y_test, predictii_knn)\n",
        "print(f\"Acuratețea modelului KNN: {acuratete_knn:.2f}\")\n",
        "\n",
        "# OBS.: scaler.fit_transform(X_train) învață media și deviația standard din\n",
        "# datele de antrenament și apoi le transformă.\n",
        "# scaler.transform(X_test) folosește aceleași valori (învățate pe train) pentru\n",
        "# a transforma datele de test.\n",
        "# Nu facem niciodată .fit() pe datele de test pentru a nu pierde informații\n",
        "# în procesul de antrenare."
      ],
      "metadata": {
        "id": "knn_example"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplu 9: KNN pe setul de date Iris\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1. Scalăm datele (folosind toate cele 4 caracteristici de data aceasta)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_iris)\n",
        "X_test_scaled = scaler.transform(X_test_iris)\n",
        "\n",
        "# 2. Antrenăm modelul KNN cu K=5\n",
        "model_knn_iris = KNeighborsClassifier(n_neighbors=5)\n",
        "model_knn_iris.fit(X_train_scaled, y_train_iris)\n",
        "\n",
        "# 3. Facem predicții și evaluăm\n",
        "y_pred_knn = model_knn_iris.predict(X_test_scaled)\n",
        "\n",
        "print(\"--- Raport de Clasificare KNN ---\")\n",
        "print(classification_report(y_test_iris, y_pred_knn, target_names=iris.target_names))\n",
        "\n",
        "# OBS.: `classification_report` ne oferă o privire detaliată asupra performanței per clasă,\n",
        "# incluzând precizia, recall-ul și f1-score. Vedem că modelul KNN este extrem de performant\n",
        "# pe acest set de date."
      ],
      "metadata": {
        "id": "knn_iris_example"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# __EXERCIȚIU__\n",
        "# Se dă un set de date despre tipuri de vin, având două caracteristici:\n",
        "# - nivel_alcool\n",
        "# - intensitate_culoare\n",
        "# Eticheta este 0 pentru Vin Alb și 1 pentru Vin Roșu.\n",
        "\n",
        "X_vin = np.array([[12.5, 3.5], [13.8, 5.0], [11.5, 2.5], [14.2, 5.5], [12.0, 3.0], [13.5, 4.8]])\n",
        "y_vin = np.array([0, 1, 0, 1, 0, 1])\n",
        "\n",
        "# 1. Scalați caracteristicile folosind StandardScaler.\n",
        "# 2. Antrenați un model KNeighborsClassifier cu K=3.\n",
        "# 3. Preziceți tipul unui vin nou cu nivel_alcool=13.0 și\n",
        "# intensitate_culoare=4.0.\n",
        "\n",
        "# HINT: Nu uitați să scalați și datele noi înainte de a face predicția."
      ],
      "metadata": {
        "id": "knn_exercitiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arbori de Decizie (Decision Trees)\n",
        "\n",
        "Un **arbore de decizie** funcționează ca un joc de \"20 de întrebări\". Modelul învață o serie de reguli `if-else` pentru a împărți datele în grupuri din ce în ce mai pure. Fiecare nod din arbore reprezintă o întrebare (o condiție) despre o anumită caracteristică, iar fiecare ramură reprezintă răspunsul la acea întrebare. Frunzele arborelui conțin predicția finală.\n",
        "\n",
        "**Avantaje**:\n",
        "-   Sunt foarte ușor de interpretat și vizualizat.\n",
        "-   Nu necesită scalarea datelor.\n",
        "\n",
        "**Dezavantaje**:\n",
        "-   Pot deveni foarte complecși și pot suferi de **supra-antrenare (overfitting)**, adică memorează datele de antrenament în loc să generalizeze."
      ],
      "metadata": {
        "id": "decision_tree_intro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplu 10: Antrenarea unui Arbore de Decizie\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Folosim același set de date ca la exemplele anterioare\n",
        "X, y = make_classification(n_samples=100, n_features=2, n_informative=2,\n",
        "                           n_redundant=0, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Creăm și antrenăm modelul\n",
        "model_tree = DecisionTreeClassifier(random_state=42)\n",
        "model_tree.fit(X_train, y_train)\n",
        "\n",
        "# Facem predicții\n",
        "predictii_tree = model_tree.predict(X_test)\n",
        "\n",
        "acuratete_tree = accuracy_score(y_test, predictii_tree)\n",
        "print(f\"Acuratețea modelului Arbore de Decizie: {acuratete_tree:.2f}\")\n",
        "\n",
        "# OBS.: Parametrul `random_state` este folosit pentru a asigura\n",
        "# reproductibilitatea, deoarece algoritmul poate implica aleatorizare în\n",
        "# procesul de construcție a arborelui."
      ],
      "metadata": {
        "id": "decision_tree_example"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplu 11: Arbori de Decizie pe setul de date Iris\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "# 1. Model pe toate cele 4 caracteristici (pentru performanță)\n",
        "model_tree_iris = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "model_tree_iris.fit(X_train_iris, y_train_iris)\n",
        "y_pred_tree = model_tree_iris.predict(X_test_iris)\n",
        "\n",
        "print(\"--- Raport de Clasificare Arbore de Decizie (pe 4 caracteristici) ---\")\n",
        "print(classification_report(y_test_iris, y_pred_tree, target_names=iris.target_names))\n",
        "\n",
        "# 2. Vizualizarea structurii arborelui\n",
        "plt.figure(figsize=(15, 10))\n",
        "plot_tree(model_tree_iris, feature_names=iris.feature_names, class_names=iris.target_names, filled=True, rounded=True)\n",
        "plt.title(\"Structura Arborelui de Decizie pentru Clasificarea Iris\")\n",
        "plt.show()\n",
        "\n",
        "# OBS.: Granițele de decizie sunt formate din dreptunghiuri. Fiecare linie verticală sau orizontală\n",
        "# corespunde unei reguli (unei \"întrebări\") din arborele de decizie (de ex., \"petal length <= 2.45 cm?\")."
      ],
      "metadata": {
        "id": "tree_iris_example_with_viz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# __EXERCIȚIU__\n",
        "# Folosind setul de date cu studenți de la exercițiul anterior:\n",
        "X_studenti = np.array([[5, 10], [10, 15], [3, 8], [8, 12], [12, 18], [2, 5], [6, 11], [15, 20]])\n",
        "y_studenti = np.array([0, 1, 0, 1, 1, 0, 0, 1])\n",
        "\n",
        "# 1. Antrenați un model DecisionTreeClassifier.\n",
        "# 2. Calculați și afișați acuratețea modelului pe *întregul set de date* (din\n",
        "# moment ce nu l-am împărțit).\n",
        "\n",
        "# HINT: Puteți calcula acuratețea comparând y_studenti cu predicțiile făcute pe\n",
        "# X_studenti."
      ],
      "metadata": {
        "id": "decision_tree_exercitiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___"
      ],
      "metadata": {
        "id": "separator_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Capitol 4: Validare Încrucișată și Modele Complexe\n",
        "\n",
        "O singură împărțire `train_test_split` poate fi uneori norocoasă (sau ghinionistă). Pentru o evaluare mai robustă a modelului, folosim o tehnică numită **validare încrucișată (Cross-Validation)**."
      ],
      "metadata": {
        "id": "capitol_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Fold Cross-Validation\n",
        "\n",
        "Cea mai comună tehnică este **K-Fold CV**. Aceasta funcționează astfel:\n",
        "1.  Împărțim setul de date de antrenament în `K` \"fold-uri\" (bucăți) egale (de obicei K=5 sau K=10).\n",
        "2.  Executăm un ciclu de `K` ori:\n",
        "    a.  La fiecare pas, folosim `K-1` fold-uri pentru a antrena modelul.\n",
        "    b.  Folosim fold-ul rămas pentru a testa modelul.\n",
        "3.  La final, facem media celor `K` scoruri de performanță obținute. Acest scor mediu este o estimare mult mai stabilă a performanței modelului."
      ],
      "metadata": {
        "id": "k_fold_cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplu 12: Validare încrucișată cu K-Fold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Folosim setul de date complet (X, y) generat anterior\n",
        "# și un model de Regresie Logistică\n",
        "model_logreg_cv = LogisticRegression()\n",
        "\n",
        "# Aplicăm validare încrucișată cu 5 fold-uri\n",
        "scoruri = cross_val_score(model_logreg_cv, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "print(f\"Scorurile pentru fiecare fold: {scoruri}\")\n",
        "print(f\"Acuratețea medie (Cross-Validation): {scoruri.mean():.2f}\")\n",
        "print(f\"Deviația standard a scorurilor: {scoruri.std():.2f}\")\n",
        "\n",
        "# OBS.: Deviația standard ne arată cât de mult variază performanța între diferitele împărțiri ale datelor.\n",
        "# O deviație mică sugerează un model stabil."
      ],
      "metadata": {
        "id": "k_fold_example"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}