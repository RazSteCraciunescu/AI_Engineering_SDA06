{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpTz8X-zwUp_"
      },
      "source": [
        "# Capitol 1: Introducere în Învățarea Nesupervizată"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPK-3yOcwUqA"
      },
      "source": [
        "Bun venit la cursul de Învățare Nesupervizată! Spre deosebire de învățarea supervizată (cum ar fi regresia sau clasificarea), unde avem date etichetate și un obiectiv clar (de exemplu, prezicerea unui preț sau a unei categorii), în învățarea nesupervizată explorăm date **neetichetate**. Scopul nostru este să descoperim structuri, modele sau grupuri ascunse direct în date, fără a avea un răspuns corect predefinit.\n",
        "\n",
        "Gândiți-vă la diferența dintre a sorta o cutie de piese Lego având instrucțiuni (supervizat) și a o sorta pur și simplu grupând piesele după culoare și formă, fără nicio instrucțiune (nesupervizat). În al doilea caz, descoperiți singuri categoriile."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEOyAhNjwUqB"
      },
      "source": [
        "## Sarcinile principale în Învățarea Nesupervizată\n",
        "\n",
        "Există trei mari categorii de probleme pe care le putem rezolva cu învățarea nesupervizată:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e94LHqdbwUqB"
      },
      "source": [
        "### 1. Clustering (Grupare)\n",
        "\n",
        "**Clustering-ul** este procesul de a grupa seturi de date similare în categorii sau **clustere**. Scopul este ca obiectele din același grup să fie cât mai asemănătoare între ele și cât mai diferite de obiectele din alte grupuri.\n",
        "\n",
        "**Analogia coșului cu fructe:** Imaginați-vă că aveți un coș plin cu mere, pere și căpșuni. Fără să vi se spună ce este fiecare fruct, un algoritm de clustering le-ar putea grupa în trei grămezi: una cu toate merele, una cu perele și una cu căpșunile, bazându-se pe caracteristici precum **culoare**, **formă** și **mărime**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch3LC1cowUqB"
      },
      "source": [
        "### 2. Reducerea Dimensionalității (Dimensionality Reduction)\n",
        "\n",
        "Această tehnică este folosită pentru a simplifica datele, reducând numărul de variabile (sau **dimensiuni**) luate în considerare. Se păstrează doar informațiile esențiale, eliminând zgomotul sau datele redundante. Acest lucru face ca algoritmii să ruleze mai rapid și, uneori, chiar să ofere rezultate mai bune.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DN3yeJhwUqB"
      },
      "source": [
        "### 3. Detectarea Anomaliilor (Anomaly Detection)\n",
        "\n",
        "Această sarcină se concentrează pe identificarea observațiilor, evenimentelor sau elementelor care sunt neobișnuite și diferă semnificativ de majoritatea datelor. Aceste **anomalii** pot reprezenta erori, fraude sau evenimente rare, dar importante.\n",
        "\n",
        "**Analogia mașinuței de jucărie:** Dacă ați avea o parcare plină de mașini reale și o singură mașinuță de jucărie, un algoritm de detectare a anomaliilor ar semnala imediat mașinuța ca fiind un element neobișnuit, care nu se potrivește cu restul."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1xYs0HuwUqB"
      },
      "outputs": [],
      "source": [
        "# __EXERCIȚIU__\n",
        "# Pentru fiecare scenariu de mai jos, identificați dacă este o problemă de:\n",
        "# A) Învățare Supervizată - Clasificare\n",
        "# B) Învățare Supervizată - Regresie\n",
        "# C) Învățare Nesupervizată - Clustering\n",
        "# Scrieți litera corespunzătoare în variabilele de mai jos (ex: raspuns_1 = 'A').\n",
        "\n",
        "# 1. O companie de marketing vrea să împartă clienții în grupuri pe baza\n",
        "# comportamentului lor de cumpărare pentru a trimite oferte personalizate.\n",
        "raspuns_1 = ''\n",
        "\n",
        "# 2. O bancă dorește să prezică dacă un client va rambursa sau nu un credit, pe\n",
        "# baza istoricului său financiar.\n",
        "raspuns_2 = ''\n",
        "\n",
        "# 3. O agenție imobiliară vrea să estimeze prețul unei case pe baza suprafeței,\n",
        "# numărului de camere și a locației.\n",
        "raspuns_3 = ''\n",
        "\n",
        "# 4. Un serviciu de streaming de muzică vrea să recomande utilizatorilor melodii\n",
        "# noi, grupând melodiile cu caracteristici audio similare.\n",
        "raspuns_4 = ''\n",
        "\n",
        "# HINT: Gândiți-vă dacă există o valoare țintă (etichetă) pe care încercăm să o\n",
        "# prezicem.\n",
        "# Dacă da -> Supervizat.\n",
        "#   Dacă valoarea este o categorie -> Clasificare\n",
        "#   Dacă este un număr -> Regresie.\n",
        "# Dacă nu avem o valoare țintă și doar explorăm datele pentru a găsi grupuri\n",
        "# -> Nesupervizat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce5WxRRzwUqC"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5ZrtKWUwUqC"
      },
      "source": [
        "# Capitol 2: Clustering - Măsuri de Evaluare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk5GZZpiwUqC"
      },
      "source": [
        "Cum știm dacă un algoritm de clustering și-a făcut treaba bine? Deoarece nu avem etichete cu care să comparăm rezultatul, trebuie să ne bazăm pe **măsuri interne**. Acestea evaluează calitatea clusterelor create folosind doar datele și structura grupurilor.\n",
        "\n",
        "O grupare bună are două calități esențiale:\n",
        "* **Similaritate intra-cluster ridicată**: Punctele din același cluster sunt foarte apropiate și asemănătoare.\n",
        "* **Similaritate inter-cluster scăzută**: Clusterele diferite sunt bine separate și distincte unele de altele.\n",
        "\n",
        "**Analogia insulelor:** Un clustering bun este ca un arhipelag de insule distincte. Fiecare insulă (cluster) este compactă, cu toate punctele de pe ea apropiate (similaritate intra-cluster ridicată). În același timp, insulele sunt separate de porțiuni mari de apă (similaritate inter-cluster scăzută)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET_Il0F0wUqC"
      },
      "source": [
        "## Suma Erorilor Pătratice (Sum of Squared Errors - SSE)\n",
        "\n",
        "SSE, cunoscută și sub numele de **inerție**, măsoară cât de compacte sunt clusterele. Pentru fiecare cluster, se calculează suma distanțelor pătratice dintre fiecare punct și **centroidul** (centrul) clusterului respectiv. SSE total este suma acestor valori pentru toate clusterele.\n",
        "\n",
        "O valoare **mică** a SSE indică faptul că punctele sunt strâns grupate în jurul centrelor lor, deci clusterele sunt dense și compacte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDtVvLRKwUqC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Exemplu 1: Două clustere, unul compact și unul dispersat\n",
        "cluster_compact = np.array([[1, 2], [2, 2], [1, 3]])\n",
        "cluster_dispersat = np.array([[8, 8], [10, 10], [12, 8]])\n",
        "\n",
        "# Calculăm centroizii (media pe fiecare axă)\n",
        "centroid_compact = cluster_compact.mean(axis=0)\n",
        "centroid_dispersat = cluster_dispersat.mean(axis=0)\n",
        "\n",
        "# Calculăm SSE pentru fiecare cluster\n",
        "# np.sum((cluster - centroid)**2) calculează distanța euclidiană pătratică\n",
        "sse_compact = np.sum((cluster_compact - centroid_compact)**2)\n",
        "sse_dispersat = np.sum((cluster_dispersat - centroid_dispersat)**2)\n",
        "\n",
        "print(f\"Centroid cluster compact: {centroid_compact}\")\n",
        "print(f\"SSE cluster compact: {sse_compact:.2f}\")\n",
        "print(f\"Centroid cluster dispersat: {centroid_dispersat}\")\n",
        "print(f\"SSE cluster dispersat: {sse_dispersat:.2f}\")\n",
        "\n",
        "# OBS.: Clusterul compact are o valoare SSE mult mai mică, ceea ce reflectă\n",
        "# corect faptul că punctele sale sunt mai apropiate.\n",
        "# O problemă cu SSE este că valoarea sa va scădea mereu pe măsură ce adăugăm mai\n",
        "# multe clustere.\n",
        "# În cazul extrem, dacă fiecare punct este propriul său cluster, SSE va fi 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCepxqTYwUqD"
      },
      "outputs": [],
      "source": [
        "# __EXERCIȚIU__\n",
        "# Se dă un nou cluster de puncte. Calculați centroidul și valoarea SSE.\n",
        "cluster_nou = np.array([[5, 5], [5, 6], [6, 5], [6, 6], [10,10]])\n",
        "\n",
        "# 1. Calculați centroidul clusterului\n",
        "centroid_nou = None\n",
        "\n",
        "# 2. Calculați SSE pentru cluster\n",
        "sse_nou = None\n",
        "\n",
        "print(f\"Centroid: {centroid_nou}\")\n",
        "print(f\"SSE: {sse_nou}\")\n",
        "\n",
        "# HINT: Folosiți metodele .mean() și funcția np.sum() ca în exemplul de mai sus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpwmqsKKwUqD"
      },
      "source": [
        "## Coeficientul Silhouette\n",
        "\n",
        "Coeficientul Silhouette este o măsură mai complexă care evaluează atât cât de bine este grupat un punct în propriul cluster (**coeziune**), cât și cât de bine este separat de celelalte clustere (**separație**). Scorul variază între **-1** și **1**:\n",
        "\n",
        "* Un scor aproape de **+1** indică faptul că punctul este departe de clusterele vecine (separare bună).\n",
        "* Un scor de **0** indică faptul că punctul este foarte aproape de granița dintre două clustere.\n",
        "* Un scor aproape de **-1** indică faptul că punctul ar putea fi atribuit greșit unui cluster.\n",
        "\n",
        "Pentru un set de date, se calculează scorul Silhouette mediu pentru toate punctele. O valoare medie mai mare indică un clustering mai bun."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBv_sMvUwUqD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "# Exemplu 2: Generăm date și etichete pentru a folosi silhouette_score\n",
        "X, y_true = make_blobs(n_samples=100, centers=2, cluster_std=0.80, random_state=42)\n",
        "\n",
        "# Presupunem că un algoritm de clustering a generat aceste etichete (perfecte,\n",
        "# în acest caz)\n",
        "y_pred = y_true\n",
        "\n",
        "score = silhouette_score(X, y_pred)\n",
        "print(f\"Scorul Silhouette pentru acest clustering este: {score:.2f}\")\n",
        "\n",
        "# Vizualizare\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.title(f\"Clustering cu Scorul Silhouette de {score:.2f}\")\n",
        "plt.show()\n",
        "\n",
        "# OBS.: silhouette_score din sklearn este un instrument puternic pentru a\n",
        "# compara performanța diferitor algoritmi de clustering sau a diferitor numere\n",
        "# de clustere (k)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQfNPAzEwUqD"
      },
      "outputs": [],
      "source": [
        "# __EXERCIȚIU__\n",
        "# Se dau aceleași date X de mai sus, dar de data aceasta, etichetele prezise\n",
        "# (y_pred_rau) sunt amestecate.\n",
        "# Calculați scorul Silhouette pentru acest clustering \"rău\" și observați\n",
        "# diferența.\n",
        "\n",
        "# Amestecăm etichetele pentru a simula un clustering prost\n",
        "y_pred_rau = np.random.permutation(y_true)\n",
        "\n",
        "# Calculați scorul Silhouette\n",
        "score_rau = None\n",
        "print(f\"Scorul Silhouette pentru clustering-ul rău este: {score_rau:.2f}\")\n",
        "\n",
        "# Vizualizare\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_pred_rau, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.title(f\"Clustering rău, Scorul Silhouette: {score_rau:.2f}\")\n",
        "plt.show()\n",
        "\n",
        "# HINT: Scorul ar trebui să fie semnificativ mai mic, posibil chiar negativ,\n",
        "# indicând că punctele sunt amestecate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNHh0SpLwUqD"
      },
      "source": [
        "## Problema Măsurilor Interne\n",
        "Măsurile interne precum SSE și Silhouette sunt utile, dar au o limitare importantă: majoritatea presupun că clusterele sunt **convexe** și **izotrope** (de formă sferică și cu densitate similară). Ele pot evalua greșit un clustering care este de fapt corect, dar are o formă complexă.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wzdrdac9wUqD"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_circles\n",
        "\n",
        "# Exemplu 3: Generăm date care formează două cercuri concentrice\n",
        "X_cercuri, y_cercuri = make_circles(n_samples=200, factor=0.5, noise=0.05, random_state=0)\n",
        "\n",
        "# Acestea sunt etichetele corecte, care separă perfect cercurile\n",
        "score_cercuri = silhouette_score(X_cercuri, y_cercuri)\n",
        "\n",
        "print(f\"Scorul Silhouette pentru clustering-ul perfect al cercurilor este: {score_cercuri:.2f}\")\n",
        "\n",
        "# Vizualizare\n",
        "plt.scatter(X_cercuri[:, 0], X_cercuri[:, 1], c=y_cercuri, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.title(f\"Clustering corect, dar cu un scor Silhouette mic: {score_cercuri:.2f}\")\n",
        "plt.show()\n",
        "\n",
        "# OBS.: Deși vizual gruparea este perfectă, scorul Silhouette este mic.\n",
        "# Asta se întâmplă deoarece metrica nu poate înțelege că un cluster poate fi\n",
        "# \"în interiorul\" altuia.\n",
        "# Acest exemplu subliniază importanța de a alege o metrică și un algoritm\n",
        "# potrivite pentru structura datelor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQSNq6HEwUqD"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jfZFnJmwUqD"
      },
      "source": [
        "# Capitol 3: Algoritmi de Clustering Bazați pe Centroizi: K-Means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTROJICewUqD"
      },
      "source": [
        "**K-Means** este unul dintre cei mai cunoscuți și utilizați algoritmi de clustering. Este un algoritm bazat pe **centroizi**, ceea ce înseamnă că grupează datele încercând să minimizeze distanța dintre puncte și centrul clusterului din care fac parte.\n",
        "\n",
        "Principalul său avantaj este viteza și simplitatea, dar necesită ca noi să specificăm de la început numărul de clustere (**k**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUhjp5znwUqE"
      },
      "source": [
        "## Cum funcționează K-Means?\n",
        "\n",
        "Algoritmul funcționează iterativ, în trei pași:\n",
        "\n",
        "1.  **Inițializare**: Se aleg aleatoriu **k** puncte din setul de date, care vor fi centroizii inițiali.\n",
        "2.  **Atribuire**: Fiecare punct din setul de date este atribuit celui mai apropiat centroid, formând astfel **k** clustere.\n",
        "3.  **Actualizare**: Pentru fiecare cluster nou format, se recalculează centroidul (ca fiind media tuturor punctelor din acel cluster).\n",
        "\n",
        "Pașii 2 și 3 se repetă până când centroizii nu își mai modifică poziția semnificativ, adică până când clusterele se stabilizează."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d47oSjpgwUqE"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Exemplu 1: Aplicăm KMeans pe un set de date generat\n",
        "X, y = make_blobs(n_samples=300, centers=4, cluster_std=0.9, random_state=0)\n",
        "\n",
        "# Inițializăm modelul KMeans, specificând că vrem 4 clustere\n",
        "kmeans = KMeans(n_clusters=4, n_init='auto', random_state=0)\n",
        "\n",
        "# Antrenăm modelul și prezicem clusterele\n",
        "y_kmeans = kmeans.fit_predict(X)\n",
        "\n",
        "# Vizualizăm rezultatul\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
        "\n",
        "# Afișăm centroizii găsiți de algoritm\n",
        "centers = kmeans.cluster_centers_\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.75, marker='X')\n",
        "plt.title(\"Clustering cu K-Means\")\n",
        "plt.show()\n",
        "\n",
        "# OBS.: Parametrul n_init='auto' este important. Algoritmul va rula de mai multe\n",
        "# ori cu centroizi inițiali diferiți și va alege rezultatul cu cea mai mică\n",
        "# inerție (SSE), pentru a evita convergența către o soluție proastă."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4CchpifwUqE"
      },
      "outputs": [],
      "source": [
        "# __EXERCIȚIU__\n",
        "# Folosind datele de mai sus (X), aplicați algoritmul KMeans încercând să\n",
        "# grupați datele în k=3 clustere.\n",
        "# Apoi, vizualizați rezultatul, inclusiv centroizii.\n",
        "\n",
        "# 1. Inițializați modelul KMeans pentru k=3\n",
        "kmeans_3 = None\n",
        "\n",
        "# 2. Antrenați și preziceți etichetele\n",
        "y_kmeans_3 = None\n",
        "\n",
        "# 3. Obțineți centroizii\n",
        "centers_3 = None\n",
        "\n",
        "# 4. Vizualizare\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans_3, s=50, cmap='viridis')\n",
        "plt.scatter(centers_3[:, 0], centers_3[:, 1], c='red', s=200, alpha=0.75, marker='X')\n",
        "plt.title(\"Încercare de clustering cu K=3\")\n",
        "plt.show()\n",
        "\n",
        "# HINT: Urmați pașii din exemplul anterior, schimbând doar valoarea parametrului\n",
        "# n_clusters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3j8KMMiwUqE"
      },
      "source": [
        "## Alegerea Numărului Optim de Clustere (k)\n",
        "\n",
        "Cea mai mare provocare în K-Means este alegerea valorii corecte pentru **k**. Două metode populare ne ajută în această decizie:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lWUkswywUqE"
      },
      "source": [
        "### Metoda Cotului (The Elbow Method)\n",
        "Această metodă se bazează pe calcularea SSE (inerției) pentru diferite valori ale lui `k`. Pe măsură ce `k` crește, SSE scade. Reprezentăm grafic SSE în funcție de `k`. Punctul în care descreșterea SSE încetinește brusc, formând un \"cot\" pe grafic, este considerat valoarea optimă pentru `k`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62Q8fpV2wUqE"
      },
      "outputs": [],
      "source": [
        "# Exemplu 2: Găsirea valorii optime pentru k folosind Metoda Cotului\n",
        "inertia_values = []\n",
        "k_range = range(1, 11)\n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, n_init='auto', random_state=0)\n",
        "    kmeans.fit(X)\n",
        "    inertia_values.append(kmeans.inertia_)\n",
        "\n",
        "# Vizualizăm curba cotului\n",
        "plt.plot(k_range, inertia_values, marker='o')\n",
        "plt.xlabel('Numărul de clustere (k)')\n",
        "plt.ylabel('Inerție (SSE)')\n",
        "plt.title('Metoda Cotului pentru a găsi k optim')\n",
        "plt.xticks(k_range)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# OBS.: În acest grafic, \"cotul\" este vizibil la k=4, ceea ce confirmă că 4 este\n",
        "# un număr bun de clustere pentru datele noastre."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKvIzmAcwUqE"
      },
      "outputs": [],
      "source": [
        "# __EXERCIȚIU__\n",
        "# Generați un nou set de date cu 6 centre folosind make_blobs.\n",
        "# Apoi, folosiți metoda cotului pentru a determina numărul optim de clustere.\n",
        "\n",
        "# 1. Generați datele\n",
        "X_nou, y_nou = make_blobs(n_samples=400, centers=6, cluster_std=1.0, random_state=10)\n",
        "\n",
        "# 2. Calculați inerția pentru k de la 1 la 10\n",
        "inertia_nou = []\n",
        "k_range_nou = range(1, 11)\n",
        "\n",
        "for k in k_range_nou:\n",
        "    pass\n",
        "\n",
        "# 3. Plotați graficul\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6nKn2O5wUqE"
      },
      "source": [
        "### Analiza Coeficientului Silhouette\n",
        "O alternativă la metoda cotului este calcularea scorului Silhouette mediu pentru diferite valori ale lui `k`. Vom alege valoarea `k` care corespunde celui mai **mare** scor Silhouette, deoarece acest lucru indică cea mai bună combinație de coeziune și separare."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQdDEJRewUqE"
      },
      "outputs": [],
      "source": [
        "# Exemplu 3: Găsirea k optim cu Scorul Silhouette\n",
        "silhouette_values = []\n",
        "k_range_sil = range(2, 11) # Scorul Silhouette nu e definit pentru k=1\n",
        "\n",
        "for k in k_range_sil:\n",
        "    kmeans = KMeans(n_clusters=k, n_init='auto', random_state=0)\n",
        "    y_pred = kmeans.fit_predict(X)\n",
        "    silhouette_values.append(silhouette_score(X, y_pred))\n",
        "\n",
        "# Vizualizăm scorurile\n",
        "plt.plot(k_range_sil, silhouette_values, marker='o')\n",
        "plt.xlabel('Numărul de clustere (k)')\n",
        "plt.ylabel('Scorul Silhouette mediu')\n",
        "plt.title('Analiza Silhouette pentru a găsi k optim')\n",
        "plt.xticks(k_range_sil)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# OBS.: Graficul arată un vârf clar la k=4, confirmând din nou că aceasta este\n",
        "# cea mai bună alegere.\n",
        "# Această metodă este adesea mai fiabilă decât metoda cotului, dar necesită mai\n",
        "# mult timp de calcul."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-AlNiCKwUqE"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrrPs9UdwUqF"
      },
      "source": [
        "# Capitol 4: Alte Tipuri de Algoritmi de Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSVfNzCxwUqF"
      },
      "source": [
        "Deși K-Means este foarte popular, nu este potrivit pentru toate tipurile de date. Vom explora acum alți doi algoritmi importanți care pot gestiona structuri mai complexe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QniJ-AUgwUqF"
      },
      "source": [
        "## Clustering Ierarhic Aglomerativ (Agglomerative Hierarchical Clustering)\n",
        "\n",
        "Acest algoritm are o abordare **bottom-up** (de jos în sus). Inițial, fiecare punct este considerat un cluster individual. Apoi, algoritmul fuzionează iterativ cele mai apropiate două clustere, până când toate punctele ajung într-un singur mare cluster.\n",
        "\n",
        "Rezultatul este o structură arborescentă numită **dendrogramă**, care ne arată ierarhia fuziunilor. Putem apoi \"tăia\" dendrograma la o anumită înălțime pentru a obține numărul dorit de clustere. Spre deosebire de K-Means, nu trebuie să specificăm numărul de clustere de la început, ci îl putem alege ulterior, analizând dendrograma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KckmMUo_wUqF"
      },
      "outputs": [],
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "# Exemplu 1: Generăm date și vizualizăm dendrograma\n",
        "X_agg, y_agg = make_blobs(n_samples=25, centers=3, cluster_std=1.0, random_state=101)\n",
        "\n",
        "# Calculăm legăturile între puncte\n",
        "# Metoda 'ward' minimizează varianța clusterelor care sunt fuzionate\n",
        "linked = linkage(X_agg, method='ward')\n",
        "\n",
        "# Desenăm dendrograma\n",
        "plt.figure(figsize=(10, 7))\n",
        "dendrogram(linked,\n",
        "           orientation='top',\n",
        "           distance_sort='descending',\n",
        "           show_leaf_counts=True)\n",
        "plt.title('Dendrogramă pentru Clustering Ierarhic')\n",
        "plt.show()\n",
        "\n",
        "# OBS.: Dendrograma ne arată cum punctele individuale (frunzele) sunt grupate.\n",
        "# Putem alege să \"tăiem\" la o înălțime care intersectează 3 linii verticale\n",
        "# pentru a obține 3 clustere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ra04vuqOwUqF"
      },
      "outputs": [],
      "source": [
        "# __EXERCIȚIU__\n",
        "# Acum, folosiți sklearn.cluster.AgglomerativeClustering pentru a grupa datele\n",
        "# X_agg în 3 clustere.\n",
        "# Vizualizați rezultatul folosind un scatter plot.\n",
        "\n",
        "# 1. Inițializați modelul pentru 3 clustere\n",
        "cluster_agg = None\n",
        "\n",
        "# 2. Antrenați modelul și obțineți etichetele\n",
        "y_agg_pred = None\n",
        "\n",
        "# 3. Vizualizare\n",
        "plt.scatter(X_agg[:, 0], X_agg[:, 1], c=y_agg_pred, cmap='viridis', s=50)\n",
        "plt.title('Clustering Aglomerativ cu k=3')\n",
        "plt.show()\n",
        "\n",
        "# HINT: Interfața este similară cu cea de la KMeans, dar aici folosim\n",
        "# `fit_predict`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3KnXJQNwUqF"
      },
      "source": [
        "## Clustering Bazat pe Densitate: DBSCAN\n",
        "\n",
        "**DBSCAN** (Density-Based Spatial Clustering of Applications with Noise) funcționează pe un principiu diferit: definește clusterele ca fiind zone continue de **densitate ridicată**. Este foarte eficient în a descoperi clustere cu forme arbitrare și în a identifica punctele considerate **zgomot** (outliers).\n",
        "\n",
        "DBSCAN are doi parametri importanți:\n",
        "* `eps` (epsilon): Distanța maximă dintre două puncte pentru a fi considerate vecine.\n",
        "* `min_samples`: Numărul minim de puncte necesare într-o vecinătate (definită de `eps`) pentru ca un punct să fie considerat **punct central** (core point)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozhV0bNVwUqF"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "# Exemplu 2: Folosim DBSCAN pe un set de date non-convex (în formă de semilună)\n",
        "X_moons, y_moons = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
        "\n",
        "# Inițializăm și aplicăm DBSCAN\n",
        "dbscan = DBSCAN(eps=0.3, min_samples=5)\n",
        "y_dbscan = dbscan.fit_predict(X_moons)\n",
        "\n",
        "# Vizualizăm rezultatul\n",
        "plt.scatter(X_moons[:, 0], X_moons[:, 1], c=y_dbscan, cmap='viridis', s=50)\n",
        "plt.title('Clustering cu DBSCAN')\n",
        "plt.show()\n",
        "\n",
        "# OBS.: DBSCAN a identificat corect cele două clustere în formă de semilună.\n",
        "# K-Means ar fi eșuat la această sarcină. Punctele marcate cu -1 (dacă ar\n",
        "# exista) ar fi considerate zgomot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYRXK4mjwUqF"
      },
      "outputs": [],
      "source": [
        "# __EXERCIȚIU__\n",
        "# Folosiți datele X_cercuri de la capitolul anterior.\n",
        "# Aplicați DBSCAN pentru a grupa aceste date. Experimentați cu valorile `eps`\n",
        "# și `min_samples` până obțineți o separare corectă a celor două cercuri.\n",
        "\n",
        "# 1. Inițializați DBSCAN cu parametri potriviți\n",
        "dbscan_cercuri = DBSCAN(eps=0.2, min_samples=5) # Încercați să modificați eps,\n",
        "# de ex. la 0.2\n",
        "\n",
        "# 2. Antrenați și preziceți etichetele\n",
        "y_dbscan_cercuri = dbscan_cercuri.fit_predict(X_cercuri)\n",
        "\n",
        "# 3. Vizualizare\n",
        "plt.scatter(X_cercuri[:, 0], X_cercuri[:, 1], c=y_dbscan_cercuri, cmap='viridis', s=50)\n",
        "plt.title('Clustering pe cercuri cu DBSCAN')\n",
        "plt.show()\n",
        "\n",
        "# HINT: O valoare bună pentru `eps` este în jur de 0.2. Dacă `eps` este prea\n",
        "# mare, toate punctele vor fi într-un singur cluster.\n",
        "# Dacă este prea mic, multe puncte vor fi considerate zgomot."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}